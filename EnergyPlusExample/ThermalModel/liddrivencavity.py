# -*- coding: utf-8 -*-
"""LidDrivenCavity.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZffKiKbhoqkY6tu8URNTcDd5UtBgRYj3
"""
# pip install numpy 
import numpy as np
import pandas as pd
import pickle
import matplotlib.pyplot as plt
from scipy.interpolate import griddata


def main():
    # -------Initializing variables
    #Setting temp (u), vecocity (v) & pressure P node values to zero
    #2600 data points (or rows), 6 columns
    u = np.zeros((2600, 7))
    v = np.zeros((2600, 7))
    p = np.zeros((2600, 7))


    # ----------Data importing
    #first row of the CSV file should be skipped, and the actual data should start from the third row.
    d1 = pd.read_csv("ThermalModel/Simulation Results Files/v_0.01", skiprows=1)
    d2 = pd.read_csv("ThermalModel/Simulation Results Files/v_0.06", skiprows=1)
    d3 = pd.read_csv("ThermalModel/Simulation Results Files/v_0.11", skiprows=1)
    d4 = pd.read_csv("ThermalModel/Simulation Results Files/v_0.16", skiprows=1)
    d5 = pd.read_csv("ThermalModel/Simulation Results Files/v_0.21", skiprows=1)
    d6 = pd.read_csv("ThermalModel/Simulation Results Files/v_0.26", skiprows=1)
    d7 = pd.read_csv("ThermalModel/Simulation Results Files/v_0.31", skiprows=1)
    d8 = pd.read_csv("ThermalModel/Simulation Results Files/validation_0.035", skiprows=1)

    # num_rows, num_columns = d1.shape
    # print(f"The number of rows in the CSV file is: {num_rows}")
    # print(f"The number of columns in the CSV file is: {num_columns}")


    # -------Separating variables in data
    # Node number -> All rows of first column
    node_num = d1.iloc[:, 0].values
    # print(node_num)
    #x-coordinate -> Second column
    x_cor = d1.iloc[:, 1].values
    #y-coordinate -> Third column
    y_cor = d1.iloc[:, 2].values


    p[:, 0] = d1.iloc[:, 3]
    u[:, 0] = d1.iloc[:, 4]
    v[:, 0] = d1.iloc[:, 5]

    p[:, 1] = d2.iloc[:, 3]
    u[:, 1] = d2.iloc[:, 4]
    v[:, 1] = d2.iloc[:, 5]

    p[:, 2] = d3.iloc[:, 3]
    u[:, 2] = d3.iloc[:, 4]
    v[:, 2] = d3.iloc[:, 5]

    p[:, 3] = d4.iloc[:, 3]
    u[:, 3] = d4.iloc[:, 4]
    v[:, 3] = d4.iloc[:, 5]

    p[:, 4] = d5.iloc[:, 3]
    u[:, 4] = d5.iloc[:, 4]
    v[:, 4] = d5.iloc[:, 5]

    p[:, 5] = d6.iloc[:, 3]
    u[:, 5] = d6.iloc[:, 4]
    v[:, 5] = d6.iloc[:, 5]

    p[:, 6] = d7.iloc[:, 3]
    u[:, 6] = d7.iloc[:, 4]
    v[:, 6] = d7.iloc[:, 5]

    #For this example, we're trying to predict this value
    u_validation = d8.iloc[:, 4]



    #--------Singular  Value Decomposition (SVD) of matrix u
    # Using 6 modes here (1 to 6)
    output_dict = {}
    for num_modes in range(1, 7):
        U, S, V = np.linalg.svd(u, full_matrices=False) #SVD applied to u matrix. U and V are returned as reduced matrices if possible
        # Decide on the number of modes to retain based on energy threshold
        # energy_threshold = 0.999  # Adjust as needed
        # total_energy = np.sum(S**2)
        # print("Total energy:", total_energy)
        # cumulative_energy = np.cumsum(S**2) / total_energy
        # print("Cumulative energy:", cumulative_energy)
        # num_modes = np.argmax(cumulative_energy >= energy_threshold) + 1
        # print("Number of modes:", num_modes)

        # Retain selected modes
        #Decomposition matrix will be reduced from 2600 x 7 to 2600 x 1
        U_reduced = U[:, :num_modes]          #2600 x 2
        S_reduced = np.diag(S[:num_modes])    #2 x 2
        V_reduced = V[:num_modes, 1]          #2 x 1

        # Reduced order mode
        #final reduced u will be 6 x 7
        u_r = np.dot(U_reduced.T, u)

    #--------using u_r to find new velocity prediction = 0.035
        new_coeff = np.mean(u_r[:, :2], axis=1) #Calculates the avg of first two modes (or first two rows)
        u_pred = np.zeros_like(U_reduced[:, 0])  # Extracts the first column of U_reduced, representing the coefficients associated with the first mode
        error = []
        for i in range(num_modes):
            u_pred = u_pred + new_coeff[i] * U_reduced[:, i]
            err = np.max(np.abs(u_pred - u_validation))
            error.append(err)

        x_grid = np.linspace(np.min(x_cor), np.max(x_cor), 1000)
        y_grid = np.linspace(np.min(y_cor), np.max(y_cor), 1000)
        X, Y = np.meshgrid(x_grid, y_grid)

        #Interpolating predicted values onto a grid using cubic interpolation
        u_pred = griddata((x_cor, y_cor), u_pred, (X, Y), method='cubic')
        output_dict[num_modes] = u_pred
        ref = griddata((x_cor, y_cor), u_validation, (X, Y), method='cubic')
    return pickle.dumps(output_dict)
#     plt.subplot(3, 2, num_modes, aspect = 'equal')
#     plt.subplots_adjust(left=0.4, right=1.4, bottom=0.4, top=1.4, wspace=0.1, hspace=0.4)
#     plt.contourf(X, Y, u_pred, 100)
#     plt.colorbar()
#     plt.title(str(num_modes) + " modes")

# export output_dict

# plt.contourf(X, Y, ref, 100)
# plt.title('Reference')
# plt.colorbar()

# plt.plot(range(1, 7), error, linewidth=2)
# plt.xlabel('Number of modes', fontsize=18)
# plt.ylabel("Maximum absolute error", fontsize=18)

# plt.savefig("OutputImage2.pdf", format="pdf", bbox_inches="tight")
# plt.show()